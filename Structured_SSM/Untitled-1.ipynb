{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed datasets from ./processed_datasets\n",
      "Loaded dataset from ./processed_datasets/physionet2012_1_pos.h5\n",
      "Loaded dataset from ./processed_datasets/physionet2012_1_neg.h5\n",
      "Loaded dataset from ./processed_datasets/physionet2012_1_val.h5\n",
      "Loaded dataset from ./processed_datasets/physionet2012_1_test.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DL/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "  1%|          | 1/126 [00:21<45:37, 21.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: torch.Size([64, 37, 178])\n",
      "torch.Size([64, 178])\n",
      "data shape: torch.Size([64, 37, 132])\n",
      "torch.Size([64, 132])\n",
      "data shape: torch.Size([64, 37, 154])\n",
      "torch.Size([64, 154])\n",
      "data shape: torch.Size([64, 37, 190])\n",
      "torch.Size([64, 190])\n",
      "data shape: torch.Size([64, 37, 155])\n",
      "torch.Size([64, 155])\n",
      "data shape: torch.Size([64, 37, 157])\n",
      "torch.Size([64, 157])\n",
      "data shape: torch.Size([64, 37, 132])\n",
      "torch.Size([64, 132])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 8/126 [00:22<04:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: torch.Size([64, 37, 178])\n",
      "torch.Size([64, 178])\n",
      "data shape: torch.Size([64, 37, 168])\n",
      "torch.Size([64, 168])\n",
      "data shape: torch.Size([64, 37, 159])\n",
      "torch.Size([64, 159])\n",
      "data shape: torch.Size([64, 37, 159])\n",
      "torch.Size([64, 159])\n",
      "data shape: torch.Size([64, 37, 170])\n",
      "torch.Size([64, 170])\n",
      "data shape: torch.Size([64, 37, 171])\n",
      "torch.Size([64, 171])\n",
      "data shape: torch.Size([64, 37, 167])\n",
      "torch.Size([64, 167])\n",
      "data shape: torch.Size([64, 37, 172])\n",
      "torch.Size([64, 172])\n",
      "data shape: torch.Size([64, 37, 156])\n",
      "torch.Size([64, 156])\n",
      "data shape: torch.Size([64, 37, 186])\n",
      "torch.Size([64, 186])\n",
      "data shape: torch.Size([64, 37, 171])\n",
      "torch.Size([64, 171])\n",
      "data shape: torch.Size([64, 37, 163])\n",
      "torch.Size([64, 163])\n",
      "data shape: torch.Size([64, 37, 133])\n",
      "torch.Size([64, 133])\n",
      "data shape: torch.Size([64, 37, 167])\n",
      "torch.Size([64, 167])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 31/126 [00:22<00:33,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: torch.Size([64, 37, 164])\n",
      "torch.Size([64, 164])\n",
      "data shape: torch.Size([64, 37, 140])\n",
      "torch.Size([64, 140])\n",
      "data shape: torch.Size([64, 37, 146])\n",
      "torch.Size([64, 146])\n",
      "data shape: torch.Size([64, 37, 191])\n",
      "torch.Size([64, 191])\n",
      "data shape: torch.Size([64, 37, 128])\n",
      "torch.Size([64, 128])\n",
      "data shape: torch.Size([64, 37, 131])\n",
      "torch.Size([64, 131])\n",
      "data shape: torch.Size([64, 37, 162])\n",
      "torch.Size([64, 162])\n",
      "data shape: torch.Size([64, 37, 141])\n",
      "torch.Size([64, 141])\n",
      "data shape: torch.Size([64, 37, 141])\n",
      "torch.Size([64, 141])\n",
      "data shape: torch.Size([64, 37, 171])\n",
      "torch.Size([64, 171])\n",
      "data shape: torch.Size([64, 37, 126])\n",
      "torch.Size([64, 126])\n",
      "data shape: torch.Size([64, 37, 207])\n",
      "torch.Size([64, 207])\n",
      "data shape: torch.Size([64, 37, 150])\n",
      "torch.Size([64, 150])\n",
      "data shape: torch.Size([64, 37, 152])\n",
      "torch.Size([64, 152])\n",
      "data shape: torch.Size([64, 37, 162])\n",
      "torch.Size([64, 162])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 52/126 [00:22<00:10,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: torch.Size([64, 37, 139])\n",
      "torch.Size([64, 139])\n",
      "data shape: torch.Size([64, 37, 171])\n",
      "torch.Size([64, 171])\n",
      "data shape: torch.Size([64, 37, 140])\n",
      "torch.Size([64, 140])\n",
      "data shape: torch.Size([64, 37, 178])\n",
      "torch.Size([64, 178])\n",
      "data shape: torch.Size([64, 37, 146])\n",
      "torch.Size([64, 146])\n",
      "data shape: torch.Size([64, 37, 152])\n",
      "torch.Size([64, 152])\n",
      "data shape: torch.Size([64, 37, 152])\n",
      "torch.Size([64, 152])\n",
      "data shape: torch.Size([64, 37, 186])\n",
      "torch.Size([64, 186])\n",
      "data shape: torch.Size([64, 37, 152])\n",
      "torch.Size([64, 152])\n",
      "data shape: torch.Size([64, 37, 130])\n",
      "torch.Size([64, 130])\n",
      "data shape: torch.Size([64, 37, 165])\n",
      "torch.Size([64, 165])\n",
      "data shape: torch.Size([64, 37, 142])\n",
      "torch.Size([64, 142])\n",
      "data shape: torch.Size([64, 37, 133])\n",
      "torch.Size([64, 133])\n",
      "data shape: torch.Size([64, 37, 130])\n",
      "torch.Size([64, 130])\n",
      "data shape: torch.Size([64, 37, 152])\n",
      "torch.Size([64, 152])\n",
      "data shape: torch.Size([64, 37, 134])\n",
      "torch.Size([64, 134])\n",
      "data shape: torch.Size([64, 37, 168])\n",
      "torch.Size([64, 168])\n",
      "data shape: torch.Size([64, 37, 130])\n",
      "torch.Size([64, 130])\n",
      "data shape: torch.Size([64, 37, 207])\n",
      "torch.Size([64, 207])\n",
      "data shape: torch.Size([64, 37, 146])\n",
      "torch.Size([64, 146])\n",
      "data shape: torch.Size([64, 37, 146])\n",
      "torch.Size([64, 146])\n",
      "data shape: torch.Size([64, 37, 144])\n",
      "torch.Size([64, 144])\n",
      "data shape: torch.Size([64, 37, 120])\n",
      "torch.Size([64, 120])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 61/126 [00:23<00:06,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: torch.Size([64, 37, 158])\n",
      "torch.Size([64, 158])\n",
      "data shape: torch.Size([64, 37, 143])\n",
      "torch.Size([64, 143])\n",
      "data shape: torch.Size([64, 37, 203])\n",
      "torch.Size([64, 203])\n",
      "data shape: torch.Size([64, 37, 137])\n",
      "torch.Size([64, 137])\n",
      "data shape: torch.Size([64, 37, 170])\n",
      "torch.Size([64, 170])\n",
      "data shape: torch.Size([64, 37, 125])\n",
      "torch.Size([64, 125])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 76/126 [00:23<00:03, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: torch.Size([64, 37, 167])\n",
      "torch.Size([64, 167])\n",
      "data shape: torch.Size([64, 37, 160])\n",
      "torch.Size([64, 160])\n",
      "data shape: torch.Size([64, 37, 125])\n",
      "torch.Size([64, 125])\n",
      "data shape: torch.Size([64, 37, 172])\n",
      "torch.Size([64, 172])\n",
      "data shape: torch.Size([64, 37, 120])\n",
      "torch.Size([64, 120])\n",
      "data shape: torch.Size([64, 37, 121])\n",
      "torch.Size([64, 121])\n",
      "data shape: torch.Size([64, 37, 126])\n",
      "torch.Size([64, 126])\n",
      "data shape: torch.Size([64, 37, 128])\n",
      "torch.Size([64, 128])\n",
      "data shape: torch.Size([64, 37, 158])\n",
      "torch.Size([64, 158])\n",
      "data shape: torch.Size([64, 37, 165])\n",
      "torch.Size([64, 165])\n",
      "data shape: torch.Size([64, 37, 183])\n",
      "torch.Size([64, 183])\n",
      "data shape: torch.Size([64, 37, 129])\n",
      "torch.Size([64, 129])\n",
      "data shape: torch.Size([64, 37, 137])\n",
      "torch.Size([64, 137])\n",
      "data shape: torch.Size([64, 37, 157])\n",
      "torch.Size([64, 157])\n",
      "data shape: torch.Size([64, 37, 129])\n",
      "torch.Size([64, 129])\n",
      "data shape: torch.Size([64, 37, 152])\n",
      "torch.Size([64, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 94/126 [00:23<00:01, 26.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: torch.Size([64, 37, 143])\n",
      "torch.Size([64, 143])\n",
      "data shape: torch.Size([64, 37, 151])\n",
      "torch.Size([64, 151])\n",
      "data shape: torch.Size([64, 37, 144])\n",
      "torch.Size([64, 144])\n",
      "data shape: torch.Size([64, 37, 132])\n",
      "torch.Size([64, 132])\n",
      "data shape: torch.Size([64, 37, 174])\n",
      "torch.Size([64, 174])\n",
      "data shape: torch.Size([64, 37, 191])\n",
      "torch.Size([64, 191])\n",
      "data shape: torch.Size([64, 37, 143])\n",
      "torch.Size([64, 143])\n",
      "data shape: torch.Size([64, 37, 162])\n",
      "torch.Size([64, 162])\n",
      "data shape: torch.Size([64, 37, 186])\n",
      "torch.Size([64, 186])\n",
      "data shape: torch.Size([64, 37, 168])\n",
      "torch.Size([64, 168])\n",
      "data shape: torch.Size([64, 37, 130])\n",
      "torch.Size([64, 130])\n",
      "data shape: torch.Size([64, 37, 186])\n",
      "torch.Size([64, 186])\n",
      "data shape: torch.Size([64, 37, 172])\n",
      "torch.Size([64, 172])\n",
      "data shape: torch.Size([64, 37, 159])\n",
      "torch.Size([64, 159])\n",
      "data shape: torch.Size([64, 37, 141])\n",
      "torch.Size([64, 141])\n",
      "data shape: torch.Size([64, 37, 158])\n",
      "torch.Size([64, 158])\n",
      "data shape: torch.Size([64, 37, 151])\n",
      "torch.Size([64, 151])\n",
      "data shape: torch.Size([64, 37, 172])\n",
      "torch.Size([64, 172])\n",
      "data shape: torch.Size([64, 37, 152])\n",
      "torch.Size([64, 152])\n",
      "data shape: torch.Size([64, 37, 170])\n",
      "torch.Size([64, 170])\n",
      "data shape: torch.Size([64, 37, 146])\n",
      "torch.Size([64, 146])\n",
      "data shape: torch.Size([64, 37, 171])\n",
      "torch.Size([64, 171])\n",
      "data shape: torch.Size([64, 37, 129])\n",
      "torch.Size([64, 129])\n",
      "data shape: torch.Size([64, 37, 174])\n",
      "torch.Size([64, 174])\n",
      "data shape: torch.Size([64, 37, 143])\n",
      "torch.Size([64, 143])\n",
      "data shape: torch.Size([64, 37, 129])\n",
      "torch.Size([64, 129])\n",
      "data shape: torch.Size([64, 37, 135])\n",
      "torch.Size([64, 135])\n",
      "data shape: torch.Size([64, 37, 136])\n",
      "torch.Size([64, 136])\n",
      "data shape: torch.Size([64, 37, 191])\n",
      "torch.Size([64, 191])\n",
      "data shape: torch.Size([64, 37, 168])\n",
      "torch.Size([64, 168])\n",
      "data shape: torch.Size([64, 37, 147])\n",
      "torch.Size([64, 147])\n",
      "data shape: torch.Size([64, 37, 143])\n",
      "torch.Size([64, 143])\n",
      "data shape: torch.Size([64, 37, 207])\n",
      "torch.Size([64, 207])\n",
      "data shape: torch.Size([64, 37, 157])\n",
      "torch.Size([64, 157])\n",
      "data shape: torch.Size([64, 37, 186])\n",
      "torch.Size([64, 186])\n",
      "data shape: torch.Size([64, 37, 121])\n",
      "torch.Size([64, 121])\n",
      "data shape: torch.Size([64, 37, 125])\n",
      "torch.Size([64, 125])\n",
      "data shape: torch.Size([64, 37, 171])\n",
      "torch.Size([64, 171])\n",
      "data shape: torch.Size([64, 37, 186])\n",
      "torch.Size([64, 186])\n",
      "data shape: torch.Size([64, 37, 162])\n",
      "torch.Size([64, 162])\n",
      "data shape: torch.Size([64, 37, 155])\n",
      "torch.Size([64, 155])\n",
      "data shape: torch.Size([64, 37, 164])\n",
      "torch.Size([64, 164])\n",
      "data shape: torch.Size([64, 37, 151])\n",
      "torch.Size([64, 151])\n",
      "data shape: torch.Size([64, 37, 125])\n",
      "torch.Size([64, 125])\n",
      "data shape: torch.Size([52, 37, 157])\n",
      "torch.Size([52, 157])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:25<00:00,  4.96it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from mortality_part_preprocessing import load_pad_separate\n",
    "from mortality_part_preprocessing import PairedDataset\n",
    "import tqdm\n",
    "# print(os.listdir('/Users/a/Desktop/data/Structured_SSM/P12data'))\n",
    "\n",
    "# 加载 .npy 文件\n",
    "# data = np.load('/Users/a/Desktop/data/Structured_SSM/P12data/split_1/test_physionet2012_1.npy', allow_pickle=True)\n",
    "dataset_id = \"physionet2012\"\n",
    "base_path= '/Users/a/Desktop/data/Structured_SSM/P12data'\n",
    "split_index = 1\n",
    "base_path_new = f\"{base_path}/split_{split_index}\"\n",
    "train_pair, val_data, test_data = load_pad_separate(\n",
    "            dataset_id, base_path_new, split_index\n",
    "        )\n",
    "train_collate_fn = PairedDataset.paired_collate_fn_truncate\n",
    "train_dataloader = DataLoader(train_pair, 32, shuffle=True, num_workers=16, collate_fn=train_collate_fn, pin_memory=True)\n",
    "\n",
    "i = 0\n",
    "\n",
    "for batch in tqdm.tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "            data, times, static, labels, mask, delta = batch\n",
    "            i += 1\n",
    "            if i == i:\n",
    "                # print('data:', data)\n",
    "                print('data shape:', data.shape)\n",
    "                print(times.shape)\n",
    "                # print('times:'times)\n",
    "                # print(static)\n",
    "                # print(labels)\n",
    "\n",
    "\n",
    "# 查看数据的形状和类型\n",
    "# print(\"Shape:\", train_dataloader.shape)\n",
    "# print(\"Data type:\", train_dataloader.dtype)\n",
    "\n",
    "# 打印文件内容\n",
    "# print(data)\n",
    "# print(train_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Any, Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "# from transformers import BigBirdConfig, MambaConfig\n",
    "\n",
    "class TimeEmbeddingLayer(nn.Module):\n",
    "    \"\"\"Embedding layer for time features.\"\"\"\n",
    "\n",
    "    def __init__(self, embedding_size: int, is_time_delta: bool = False):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.is_time_delta = is_time_delta\n",
    "\n",
    "        self.w = nn.Parameter(torch.empty(1, self.embedding_size))\n",
    "        self.phi = nn.Parameter(torch.empty(1, self.embedding_size))\n",
    "\n",
    "        nn.init.xavier_uniform_(self.w)\n",
    "        nn.init.xavier_uniform_(self.phi)\n",
    "\n",
    "    def forward(self, time_stamps: torch.Tensor) -> Any:\n",
    "        \"\"\"Apply time embedding to the input time stamps.\"\"\"\n",
    "\n",
    "        if self.is_time_delta:\n",
    "            # If the time_stamps represent time deltas, we calculate the deltas.\n",
    "            # This is equivalent to the difference between consecutive elements.\n",
    "            time_stamps = torch.cat(\n",
    "                (time_stamps[:, 0:1] * 0, time_stamps[:, 1:] - time_stamps[:, :-1]),\n",
    "                # (time_stamps[:, 0:1], time_stamps_delta),\n",
    "                # (time_stamps, time_stamps_delta),\n",
    "                dim=-1,\n",
    "            )\n",
    "        time_stamps = time_stamps.float()\n",
    "        time_stamps_expanded = time_stamps.unsqueeze(-1)\n",
    "        next_input = time_stamps_expanded * self.w + self.phi\n",
    "        \n",
    "        # print(\"time_stamps_delta.unsqueeze(-1).shape:\", time_stamps_delta.unsqueeze(-1).shape)\n",
    "        return torch.sin(next_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: tensor([0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "labels shape: torch.Size([52])\n"
     ]
    }
   ],
   "source": [
    "print(\"labels:\", labels)\n",
    "print(\"labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: torch.Size([52, 37, 157])\n",
      "time shape: torch.Size([52, 157])\n",
      "static shape: torch.Size([52, 8])\n",
      "time shape: torch.Size([52, 157, 32])\n",
      "age: torch.Size([52])\n",
      "age_embed: torch.Size([52, 32])\n"
     ]
    }
   ],
   "source": [
    "# print(\"data:\", data)\n",
    "print(\"data shape:\", data.shape)\n",
    "# print(\"times:\", times[6])\n",
    "print(\"time shape:\", times.shape)\n",
    "# print(\"labels:\", labels)\n",
    "# print(\"labels shape:\", labels.shape)\n",
    "# print(\"static:\", static)\n",
    "print(\"static shape:\", static.shape)\n",
    "\n",
    "\n",
    "\n",
    "time_embeddings = TimeEmbeddingLayer(\n",
    "            embedding_size=32,\n",
    "            is_time_delta=True,\n",
    "        )\n",
    "\n",
    "age_embeddings = TimeEmbeddingLayer(\n",
    "            embedding_size=32,\n",
    "        )\n",
    "\n",
    "time_stamps_embeds = time_embeddings(times)\n",
    "print('time shape:', time_stamps_embeds.shape)\n",
    "# print(time_stamps_embeds)\n",
    "\n",
    "ages = static[:,0]\n",
    "print('age:', ages.shape)\n",
    "seq_length = data.shape[-1]\n",
    "ages_embeds = age_embeddings(ages)\n",
    "print('age_embed:', ages_embeds.shape)\n",
    "ages_embeds_3d = ages_embeds.unsqueeze(1).repeat(1, seq_length, 1) # [batch_size, seq_length, embedding_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 157, 32])\n",
      "torch.Size([52, 157, 37])\n",
      "torch.Size([52, 157, 101])\n"
     ]
    }
   ],
   "source": [
    "print(ages_embeds_3d.shape)\n",
    "inputs_embeds = data.permute(0, 2, 1)\n",
    "print(inputs_embeds.shape)\n",
    "inputs_embeds1 = torch.cat(\n",
    "            (inputs_embeds, time_stamps_embeds, ages_embeds_3d),\n",
    "            dim=-1,\n",
    "        )\n",
    "print(inputs_embeds1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.3570,  0.2474],\n",
      "         [ 0.3652,  1.5392],\n",
      "         [-0.9616, -0.0199]],\n",
      "\n",
      "        [[-1.6591, -0.1162],\n",
      "         [-0.0983,  1.4548],\n",
      "         [-0.9806, -1.6721]]])\n",
      "tensor([[-1.3570,  0.3652, -0.9616,  0.2474,  1.5392, -0.0199],\n",
      "        [-1.6591, -0.0983, -0.9806, -0.1162,  1.4548, -1.6721]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设你的输入数据\n",
    "data = torch.randn(2, 3, 2)  # 输入形状为 [64, 37, 180]\n",
    "print(data)\n",
    "\n",
    "# 转置数据，使每一组的 37 个元素变为行，对应第三维（180 组）\n",
    "data_transposed = data.permute(0, 2, 1)  # 形状变为 [64, 180, 37]\n",
    "\n",
    "# 将 37 和 180 展平为一维\n",
    "data_reshaped = data_transposed.reshape(2, -1)  # 形状变为 [64, 37 * 180]\n",
    "print(data_reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
